# KnowWhere Memory MCP Server

**The persistent, intelligent memory layer that makes AI agents remember everything‚Äîdeployable anywhere, integrated nowhere.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-ready-blue.svg)](https://www.docker.com/)

## üéØ Was ist KnowWhere?

KnowWhere ist ein **persistentes Ged√§chtnissystem** f√ºr AI-Agenten. Es speichert Pr√§ferenzen, Fakten, Learnings und Erkenntnisse aus Konversationen und macht sie projekt√ºbergreifend abrufbar.

### Das Problem
- Claude/GPT vergessen alles nach jeder Session
- Kontext geht verloren zwischen Projekten
- Du musst dich st√§ndig wiederholen

### Die L√∂sung
- **Semantische Suche** √ºber alle gespeicherten Erinnerungen
- **Automatische Extraktion** wichtiger Claims aus Konversationen
- **Projekt√ºbergreifend** - Erinnerungen folgen dir √ºberall hin

---

## ‚ú® Key Features

| Feature | Beschreibung |
|---------|--------------|
| üß† **Multimodale Memories** | Episodic, Semantic, Preference, Procedural, Meta |
| üöÄ **Batch Processing** | Parallele Verarbeitung f√ºr bis zu 5x schnellere Konsolidierung |
| üîç **Semantische Suche** | Vector Similarity mit pgvector (1408 Dimensionen) + Sampling |
| üîÑ **Session Consolidation** | Automatische Claim-Extraktion mit paralleler Entity-Verarbeitung |
| üìä **Evolution Tracking** | Verfolge wie sich Pr√§ferenzen √§ndern |
| üîí **GDPR Compliant** | Export und L√∂schung aller Daten |
| üåê **Vendor Agnostic** | Funktioniert mit Claude, GPT, Grok, Gemini via MCP |
| üì° **MCP Resources** | Vollst√§ndige MCP Integration mit Resources, Prompts & Roots |
| üèóÔ∏è **Dependency Injection** | Saubere Architektur f√ºr Testbarkeit und Erweiterbarkeit |

---

## üöÄ Quick Start (Docker + Supabase)

### Voraussetzungen
- Docker & Docker Compose
- [Supabase](https://supabase.com) Account (kostenlos)
- OpenAI API Key (f√ºr Embeddings)
- Anthropic API Key (f√ºr LLM)

### 1. Repository klonen

```bash
git clone https://github.com/nimarfranklin/KW_Mem_MCP_Server.git
cd KW_Mem_MCP_Server
```

### 2. Supabase Projekt erstellen

1. Gehe zu [supabase.com](https://supabase.com) ‚Üí New Project
2. Aktiviere die **pgvector Extension** unter Database ‚Üí Extensions
3. Kopiere die Credentials:
   - Project URL
   - Anon Key
   - **Session Pooler** Database URL (unter Settings ‚Üí Database ‚Üí Connection string)

### 3. Umgebungsvariablen konfigurieren

```bash
cp .env.example .env
```

Editiere `.env`:

```env
# Supabase
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
DATABASE_URL=postgresql://postgres.xxxxx:PASSWORD@aws-0-eu-central-1.pooler.supabase.com:5432/postgres

# API Keys
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-api03-...
LLM_PROVIDER=anthropic

# Optional
REDIS_URL=redis://localhost:6379
DEBUG=true
JWT_SECRET_KEY=dein-geheimer-key-min-32-zeichen
```

### 4. Datenbank-Migration ausf√ºhren

F√ºhre die Migration in Supabase SQL Editor aus:
- `supabase/migrations/20260117190000_initial_schema.sql`

### 5. Docker starten

```bash
# Mit Supabase als externe DB (empfohlen)
docker compose -f docker-compose.yml -f docker-compose.supabase.yml up -d

# Logs pr√ºfen
docker compose -f docker-compose.yml -f docker-compose.supabase.yml logs -f app
```

### 6. In Cursor integrieren

√ñffne Cursor Settings ‚Üí MCP ‚Üí Add Server:

```json
{
  "knowwhere": {
    "url": "http://localhost:8000/sse"
  }
}
```

---

## üéÆ Verwendung in Cursor

### Mit @knowwhere Mention (empfohlen)

```
@knowwhere Was ist mein Lieblingsprojekt?
```

### Automatische Nutzung

Installiere die Cursor Rule f√ºr automatische Memory-Suche:

```bash
mkdir -p ~/.cursor/rules
cp .cursor/rules/knowwhere-memory.mdc ~/.cursor/rules/
```

Jetzt wird Claude automatisch in Memories suchen bei Fragen wie:
- "Was bevorzuge ich f√ºr..."
- "Was ist mein Lieblings..."
- "Erinnerst du dich an..."

---

## üõ†Ô∏è MCP Tools

### Memory Management Tools

#### `mcp_remember` - Memory speichern
```json
{
  "content": "User bevorzugt TypeScript √ºber JavaScript",
  "memory_type": "preference",
  "importance": 8,
  "entities": ["TypeScript", "JavaScript"]
}
```

#### `mcp_recall` - Memory suchen (mit Sampling)
```json
{
  "query": "Welche Programmiersprache bevorzugt der User?",
  "filters": {"memory_type": "preference"},
  "limit": 5,
  "offset": 0,
  "include_sampling": false
}
```

#### `mcp_consolidate_session` - Konversation analysieren
```json
{
  "session_transcript": "User: Ich liebe Rust f√ºr Systems Programming...",
  "conversation_id": "session-123"
}
```

#### `mcp_analyze_evolution` - Ver√§nderungen tracken
```json
{
  "entity_name": "TypeScript",
  "time_window": "last_30_days"
}
```

#### `mcp_export_memories` - Daten exportieren
```json
{
  "format": "json",
  "include_embeddings": false
}
```

#### `mcp_delete_memory` - Memory l√∂schen
```json
{
  "memory_id": "uuid-hier",
  "hard_delete": false
}
```

### MCP Resources (Neu!)

#### `health://status` - Server Health Check
```json
{
  "status": "healthy",
  "database": "connected",
  "cache": "connected",
  "version": "1.0.0"
}
```

#### `system://capabilities` - System Features
```json
{
  "memory_types": ["episodic", "semantic", "preference", "procedural", "meta"],
  "features": {
    "batch_processing": true,
    "parallel_processing": true,
    "knowledge_graph": true
  }
}
```

#### `user://{user_id}/stats` - User Statistics
```json
{
  "total_memories": 42,
  "by_type": {
    "preference": 15,
    "semantic": 20,
    "episodic": 7
  },
  "avg_importance": 6.8
}
```

#### `user://{user_id}/preferences` - User Preferences
```json
{
  "preferences": [
    {
      "content": "Bevorzugt TypeScript √ºber JavaScript",
      "importance": 8,
      "entities": ["TypeScript", "JavaScript"]
    }
  ]
}
```

### MCP Prompts (Neu!)

#### `memory_guided_creation` - Gef√ºhrte Memory-Erstellung
Interaktiver Prompt f√ºr strukturierte Memory-Erstellung mit Best Practices.

#### `preference_analysis` - Pr√§ferenz-Analyse
Umfassende Analyse aller User-Pr√§ferenzen und Muster-Erkennung.

#### `learning_session_analysis` - Lern-Session Analyse
Spezialisiert auf die Verarbeitung von Lern-Konversationen.

#### `troubleshooting_workflow` - Troubleshooting Workflow
Systematische Probleml√∂sung mit Memory-Kontext.

---

## üèóÔ∏è Architektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AI Clients (Cursor, Claude Desktop)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ MCP Protocol (SSE + Resources)
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FastMCP Server (Docker)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              6 MCP Tools + Resources                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Tools: remember | recall | consolidate | analyze |   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ         export | delete                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Resources: health | stats | preferences | entities   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Prompts: guided_creation | preference_analysis       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ           Optimized Memory Engine                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Batch MemoryProcessor | Parallel ConsolidationEngine ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  KnowledgeGraph | Dependency Injection Container      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                          ‚îÇ                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              External Services                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    Supabase (pgvector)  |  Redis  |  OpenAI/Anthropic ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Projektstruktur

```
KW_Mem_MCP_Server/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastMCP Entry Point (SSE Transport)
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Pydantic Settings
‚îÇ   ‚îú‚îÄ‚îÄ tools/               # MCP Tool Implementierungen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ remember.py      # Memory speichern
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ recall.py        # Semantische Suche
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consolidate.py   # Session-Analyse
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyze.py       # Evolution Tracking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ export.py        # Daten-Export
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ delete.py        # Memory l√∂schen
‚îÇ   ‚îú‚îÄ‚îÄ engine/              # Business Logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_processor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consolidation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ knowledge_graph.py
‚îÇ   ‚îú‚îÄ‚îÄ storage/             # Data Access Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py      # asyncpg Pool
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cache.py         # Redis Client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ repositories/    # CRUD Operations
‚îÇ   ‚îú‚îÄ‚îÄ services/            # External APIs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py     # OpenAI Embeddings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm.py           # Anthropic/OpenAI LLM
‚îÇ   ‚îî‚îÄ‚îÄ models/              # Pydantic Models
‚îú‚îÄ‚îÄ migrations/              # SQL Migrations
‚îú‚îÄ‚îÄ supabase/migrations/     # Supabase-spezifische Migrations
‚îú‚îÄ‚îÄ tests/                   # Pytest Test Suite
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ ingest_codebase.py   # Codebase in Memories laden
‚îú‚îÄ‚îÄ .cursor/rules/           # Cursor Rules f√ºr Auto-Recall
‚îú‚îÄ‚îÄ docker-compose.yml       # Lokale Entwicklung
‚îú‚îÄ‚îÄ docker-compose.supabase.yml  # Supabase Override
‚îú‚îÄ‚îÄ Dockerfile               # Production Container
‚îî‚îÄ‚îÄ railway.toml             # Railway Deployment
```

---

## üîß Entwicklung

### Lokale Entwicklung (ohne Docker)

```bash
# Virtual Environment
python3.11 -m venv venv
source venv/bin/activate

# Dependencies
pip install -r requirements.txt

# Server starten (stdio f√ºr lokale Entwicklung)
python -m src.main
```

### Tests ausf√ºhren

```bash
# Alle Tests
pytest

# Mit Coverage
pytest --cov=src

# Nur Unit Tests
pytest tests/test_tools/ tests/test_engine/

# Integration Tests (ben√∂tigt echte DB)
pytest tests/test_real_database.py -v
```

### Codebase in KnowWhere laden

```bash
# Indexiere die gesamte Codebase f√ºr semantische Suche
python scripts/ingest_codebase.py
```

---

## üêõ Troubleshooting

### Container ist "unhealthy"
Das `/health` Endpoint existiert nicht bei FastMCP - kann ignoriert werden. Die MCP-Funktionalit√§t ist nicht betroffen.

### "Tool not found" in Cursor
1. MCP Status pr√ºfen (Cursor ‚Üí Settings ‚Üí MCP)
2. Disconnecten und neu connecten
3. Cursor neu starten

### Memories werden nicht gefunden
**User-ID Mismatch!** Stelle sicher, dass die gleiche User-ID f√ºr Speichern und Abrufen verwendet wird.

In `src/main.py`:
```python
DEFAULT_USER_ID = UUID("deine-user-id-hier")
```

### "Connection refused" zu Supabase
Verwende die **Session Pooler** URL (Port 5432), nicht die Direct Connection URL.

### Redis nicht erreichbar
Redis ist optional. Der Server funktioniert auch ohne Cache, aber langsamer.

---

## üö¢ Production Deployment

### Railway (empfohlen)

1. Fork zu deinem GitHub
2. Neues Railway Projekt erstellen
3. Add-ons: PostgreSQL, Redis
4. Environment Variables setzen
5. `railway.toml` wird automatisch erkannt

### Docker (Self-Hosted)

```bash
# Build
docker build -t knowwhere-mcp:latest .

# Run
docker run -d \
  --name knowwhere \
  -p 8000:8000 \
  -e DATABASE_URL="postgresql://..." \
  -e OPENAI_API_KEY="sk-..." \
  -e ANTHROPIC_API_KEY="sk-ant-..." \
  -e MCP_TRANSPORT="sse" \
  knowwhere-mcp:latest
```

---

## üìö Erkenntnisse aus der Entwicklung

### Wichtige Design-Entscheidungen

1. **SSE Transport f√ºr Docker**: stdio funktioniert nicht in containerisierten Umgebungen. Verwende `MCP_TRANSPORT=sse`.

2. **User-ID Management**: Im Debug-Modus wird eine Default-User-ID verwendet. Stelle sicher, dass alle Memories unter der gleichen ID gespeichert werden.

3. **Cursor Rules**: Claude entscheidet selbst, wann es Tools nutzt. Mit einer Cursor Rule kannst du automatische Memory-Suche erzwingen.

4. **Supabase Session Pooler**: Verwende die Session Pooler URL (5432) statt Direct Connection f√ºr bessere Performance.

5. **Claim Extraction**: Der LLM-Prompt f√ºr Claim-Extraktion ist kritisch. Aktuell optimiert f√ºr:
   - Pers√∂nliche Pr√§ferenzen (Wichtigkeit 8-10)
   - Projekt-Fakten (Wichtigkeit 6-8)
   - Learnings und Erkenntnisse (Wichtigkeit 5-7)
   - Entscheidungen (Wichtigkeit 7-9)

6. **JSONB Handling**: PostgreSQL JSONB Felder m√ºssen explizit zu JSON-Strings konvertiert werden beim INSERT und beim SELECT zur√ºck geparst werden.

---

## ü§ù Contributing

1. Fork das Repository
2. Feature Branch erstellen (`git checkout -b feature/amazing-feature`)
3. √Ñnderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request √∂ffnen

---

## üìÑ License

MIT License - siehe [LICENSE](LICENSE) f√ºr Details.

---

## üîó Links

- **Repository**: [github.com/nimarfranklin/KW_Mem_MCP_Server](https://github.com/nimarfranklin/KW_Mem_MCP_Server)
- **MCP Protocol**: [modelcontextprotocol.io](https://modelcontextprotocol.io)
- **Supabase**: [supabase.com](https://supabase.com)
- **FastMCP**: [github.com/jlowin/fastmcp](https://github.com/jlowin/fastmcp)

---

## üìã Recent Updates (v1.1.0)

### üöÄ Performance Optimierungen
- **5x schnellere Consolidation**: Parallele Entity Extraction und Batch Embeddings
- **Batch Processing**: Gleichzeitige Verarbeitung mehrerer Memories
- **Optimized Connection Pooling**: Verbesserte Datenbank-Verbindungen
- **Async Improvements**: Mehr Parallelisierung in unabh√§ngigen Operationen

### üì° MCP Protocol Erweiterungen
- **Neue MCP Resources**: `health://status`, `system://capabilities`, `user://{id}/stats`, `user://{id}/preferences`, `user://{id}/memories`, `user://{id}/entities`
- **MCP Prompts**: `memory_guided_creation`, `preference_analysis`, `learning_session_analysis`, `troubleshooting_workflow`
- **Sampling Support**: Effiziente Pagination f√ºr gro√üe Resultate
- **Progress Notifications**: Fortschrittsanzeige f√ºr langlaufende Operationen

### üèóÔ∏è Architektur Verbesserungen
- **Dependency Injection Container**: Saubere Service-Management
- **Service Abstraction**: Bessere Testbarkeit und Wartbarkeit
- **Batch Memory Processing**: Neue `process_memories_batch()` Methode

### üîß Developer Experience
- **Erweiterte System Capabilities**: Detaillierte Feature-Dokumentation
- **Verbesserte Error Handling**: Bessere Fehlermeldungen und Logging
- **Performance Monitoring**: Detaillierte Statistiken und Metriken

---

## üé® Semantic Intelligence (v1.2.0)

### üåå Semantic Galaxy View
Die Knowledge Graph Visualisierung wurde komplett √ºberarbeitet:
- **Semantic Spine**: Hierarchische Cluster nach Domain -> Category -> Entities
- **Granular Code Classification**: Spezielles Verst√§ndnis f√ºr Source Code (API vs. UI vs. Core)
- **Interactive Exploration**: Expandierbare Cluster f√ºr bessere √úbersicht

### üßπ Data Quality Engine
- **Active Deduplication**: Erkennt und entfernt semantische Duplikate (>95% √Ñhnlichkeit)
- **Auto-Classification**: LLM-gest√ºtzte Kategorisierung aller Memories
- **Sprach-agnostisch**: Versteht Duplikate √ºber Sprachgrenzen hinweg (DE/EN)

---

**Made with ‚ù§Ô∏è for persistent AI memory**
