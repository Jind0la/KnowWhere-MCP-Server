# KnowWhere Memory MCP Server

**The persistent, intelligent memory layer that makes AI agents remember everythingâ€”deployable anywhere, integrated nowhere.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/Docker-ready-blue.svg)](https://www.docker.com/)

## ğŸ¯ Was ist KnowWhere?

KnowWhere ist ein **persistentes GedÃ¤chtnissystem** fÃ¼r AI-Agenten. Es speichert PrÃ¤ferenzen, Fakten, Learnings und Erkenntnisse aus Konversationen und macht sie projektÃ¼bergreifend abrufbar.

### Das Problem
- Claude/GPT vergessen alles nach jeder Session
- Kontext geht verloren zwischen Projekten
- Du musst dich stÃ¤ndig wiederholen

### Die LÃ¶sung
- **Semantische Suche** Ã¼ber alle gespeicherten Erinnerungen
- **Automatische Extraktion** wichtiger Claims aus Konversationen
- **ProjektÃ¼bergreifend** - Erinnerungen folgen dir Ã¼berall hin

---

## âœ¨ Key Features

| Feature | Beschreibung |
|---------|--------------|
| ğŸ§  **Multimodale Memories** | Episodic, Semantic, Preference, Procedural, Meta |
| ğŸš€ **Batch Processing** | Parallele Verarbeitung fÃ¼r bis zu 5x schnellere Konsolidierung |
| ğŸ” **Semantische Suche** | Vector Similarity mit pgvector (1408 Dimensionen) + Sampling |
| ğŸ”„ **Session Consolidation** | Automatische Claim-Extraktion mit paralleler Entity-Verarbeitung |
| ğŸ“Š **Evolution Tracking** | Verfolge wie sich PrÃ¤ferenzen Ã¤ndern |
| ğŸ”’ **GDPR Compliant** | Export und LÃ¶schung aller Daten |
| ğŸŒ **Vendor Agnostic** | Funktioniert mit Claude, GPT, Grok, Gemini via MCP |
| ğŸ“¡ **MCP Resources** | VollstÃ¤ndige MCP Integration mit Resources, Prompts & Roots |
| ğŸ—ï¸ **Dependency Injection** | Saubere Architektur fÃ¼r Testbarkeit und Erweiterbarkeit |

---

## ğŸš€ Quick Start (Docker + Supabase)

### Voraussetzungen
- Docker & Docker Compose
- [Supabase](https://supabase.com) Account (kostenlos)
- OpenAI API Key (fÃ¼r Embeddings)
- Anthropic API Key (fÃ¼r LLM)

### 1. Repository klonen

```bash
git clone https://github.com/nimarfranklin/KW_Mem_MCP_Server.git
cd KW_Mem_MCP_Server
```

### 2. Supabase Projekt erstellen

1. Gehe zu [supabase.com](https://supabase.com) â†’ New Project
2. Aktiviere die **pgvector Extension** unter Database â†’ Extensions
3. Kopiere die Credentials:
   - Project URL
   - Anon Key
   - **Session Pooler** Database URL (unter Settings â†’ Database â†’ Connection string)

### 3. Umgebungsvariablen konfigurieren

```bash
cp .env.example .env
```

Editiere `.env`:

```env
# Supabase
SUPABASE_URL=https://xxxxx.supabase.co
SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
DATABASE_URL=postgresql://postgres.xxxxx:PASSWORD@aws-0-eu-central-1.pooler.supabase.com:5432/postgres

# API Keys
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-api03-...
LLM_PROVIDER=anthropic

# Optional
REDIS_URL=redis://localhost:6379
DEBUG=true
JWT_SECRET_KEY=dein-geheimer-key-min-32-zeichen
```

### 4. Datenbank-Migration ausfÃ¼hren

FÃ¼hre die Migration in Supabase SQL Editor aus:
- `supabase/migrations/20260117190000_initial_schema.sql`

### 5. Docker starten

```bash
# Mit Supabase als externe DB (empfohlen)
docker compose -f docker-compose.yml -f docker-compose.supabase.yml up -d

# Logs prÃ¼fen
docker compose -f docker-compose.yml -f docker-compose.supabase.yml logs -f app
```

### 6. In Cursor integrieren

Ã–ffne Cursor Settings â†’ MCP â†’ Add Server:

```json
{
  "knowwhere": {
    "url": "http://localhost:8000/sse"
  }
}
```

---

## ğŸ® Verwendung in Cursor

### Mit @knowwhere Mention (empfohlen)

```
@knowwhere Was ist mein Lieblingsprojekt?
```

### Automatische Nutzung

Installiere die Cursor Rule fÃ¼r automatische Memory-Suche:

```bash
mkdir -p ~/.cursor/rules
cp .cursor/rules/knowwhere-memory.mdc ~/.cursor/rules/
```

Jetzt wird Claude automatisch in Memories suchen bei Fragen wie:
- "Was bevorzuge ich fÃ¼r..."
- "Was ist mein Lieblings..."
- "Erinnerst du dich an..."

---

## ğŸ› ï¸ MCP Tools

### Memory Management Tools

#### `mcp_remember` - Memory speichern
```json
{
  "content": "User bevorzugt TypeScript Ã¼ber JavaScript",
  "memory_type": "preference",
  "importance": 8,
  "entities": ["TypeScript", "JavaScript"]
}
```

#### `mcp_recall` - Memory suchen (mit Sampling)
```json
{
  "query": "Welche Programmiersprache bevorzugt der User?",
  "filters": {"memory_type": "preference"},
  "limit": 5,
  "offset": 0,
  "include_sampling": false
}
```

#### `mcp_consolidate_session` - Konversation analysieren
```json
{
  "session_transcript": "User: Ich liebe Rust fÃ¼r Systems Programming...",
  "conversation_id": "session-123"
}
```

#### `mcp_analyze_evolution` - VerÃ¤nderungen tracken
```json
{
  "entity_name": "TypeScript",
  "time_window": "last_30_days"
}
```

#### `mcp_export_memories` - Daten exportieren
```json
{
  "format": "json",
  "include_embeddings": false
}
```

#### `mcp_delete_memory` - Memory lÃ¶schen
```json
{
  "memory_id": "uuid-hier",
  "hard_delete": false
}
```

### MCP Resources (Neu!)

#### `health://status` - Server Health Check
```json
{
  "status": "healthy",
  "database": "connected",
  "cache": "connected",
  "version": "1.0.0"
}
```

#### `system://capabilities` - System Features
```json
{
  "memory_types": ["episodic", "semantic", "preference", "procedural", "meta"],
  "features": {
    "batch_processing": true,
    "parallel_processing": true,
    "knowledge_graph": true
  }
}
```

#### `user://{user_id}/stats` - User Statistics
```json
{
  "total_memories": 42,
  "by_type": {
    "preference": 15,
    "semantic": 20,
    "episodic": 7
  },
  "avg_importance": 6.8
}
```

#### `user://{user_id}/preferences` - User Preferences
```json
{
  "preferences": [
    {
      "content": "Bevorzugt TypeScript Ã¼ber JavaScript",
      "importance": 8,
      "entities": ["TypeScript", "JavaScript"]
    }
  ]
}
```

### MCP Prompts (Neu!)

#### `memory_guided_creation` - GefÃ¼hrte Memory-Erstellung
Interaktiver Prompt fÃ¼r strukturierte Memory-Erstellung mit Best Practices.

#### `preference_analysis` - PrÃ¤ferenz-Analyse
Umfassende Analyse aller User-PrÃ¤ferenzen und Muster-Erkennung.

#### `learning_session_analysis` - Lern-Session Analyse
Spezialisiert auf die Verarbeitung von Lern-Konversationen.

#### `troubleshooting_workflow` - Troubleshooting Workflow
Systematische ProblemlÃ¶sung mit Memory-Kontext.

---

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Clients (Cursor, Claude Desktop)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ MCP Protocol (SSE + Resources)
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastMCP Server (Docker)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              6 MCP Tools + Resources                   â”‚ â”‚
â”‚  â”‚  Tools: remember | recall | consolidate | analyze |   â”‚ â”‚
â”‚  â”‚         export | delete                               â”‚ â”‚
â”‚  â”‚  Resources: health | stats | preferences | entities   â”‚ â”‚
â”‚  â”‚  Prompts: guided_creation | preference_analysis       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Optimized Memory Engine                      â”‚ â”‚
â”‚  â”‚  Batch MemoryProcessor | Parallel ConsolidationEngine â”‚ â”‚
â”‚  â”‚  KnowledgeGraph | Dependency Injection Container      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              External Services                         â”‚ â”‚
â”‚  â”‚    Supabase (pgvector)  |  Redis  |  OpenAI/Anthropic â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Projektstruktur

```
KW_Mem_MCP_Server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastMCP Entry Point (SSE Transport)
â”‚   â”œâ”€â”€ config.py            # Pydantic Settings
â”‚   â”œâ”€â”€ tools/               # MCP Tool Implementierungen
â”‚   â”‚   â”œâ”€â”€ remember.py      # Memory speichern
â”‚   â”‚   â”œâ”€â”€ recall.py        # Semantische Suche
â”‚   â”‚   â”œâ”€â”€ consolidate.py   # Session-Analyse
â”‚   â”‚   â”œâ”€â”€ analyze.py       # Evolution Tracking
â”‚   â”‚   â”œâ”€â”€ export.py        # Daten-Export
â”‚   â”‚   â””â”€â”€ delete.py        # Memory lÃ¶schen
â”‚   â”œâ”€â”€ engine/              # Business Logic
â”‚   â”‚   â”œâ”€â”€ memory_processor.py
â”‚   â”‚   â”œâ”€â”€ consolidation.py
â”‚   â”‚   â”œâ”€â”€ entity_extractor.py
â”‚   â”‚   â””â”€â”€ knowledge_graph.py
â”‚   â”œâ”€â”€ storage/             # Data Access Layer
â”‚   â”‚   â”œâ”€â”€ database.py      # asyncpg Pool
â”‚   â”‚   â”œâ”€â”€ cache.py         # Redis Client
â”‚   â”‚   â””â”€â”€ repositories/    # CRUD Operations
â”‚   â”œâ”€â”€ services/            # External APIs
â”‚   â”‚   â”œâ”€â”€ embedding.py     # OpenAI Embeddings
â”‚   â”‚   â””â”€â”€ llm.py           # Anthropic/OpenAI LLM
â”‚   â””â”€â”€ models/              # Pydantic Models
â”œâ”€â”€ migrations/              # SQL Migrations
â”œâ”€â”€ supabase/migrations/     # Supabase-spezifische Migrations
â”œâ”€â”€ tests/                   # Pytest Test Suite
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest_codebase.py   # Codebase in Memories laden
â”œâ”€â”€ .cursor/rules/           # Cursor Rules fÃ¼r Auto-Recall
â”œâ”€â”€ docker-compose.yml       # Lokale Entwicklung
â”œâ”€â”€ docker-compose.supabase.yml  # Supabase Override
â”œâ”€â”€ Dockerfile               # Production Container
â””â”€â”€ railway.toml             # Railway Deployment
```

---

## ğŸ”§ Entwicklung

### Lokale Entwicklung (ohne Docker)

```bash
# Virtual Environment
python3.11 -m venv venv
source venv/bin/activate

# Dependencies
pip install -r requirements.txt

# Server starten (stdio fÃ¼r lokale Entwicklung)
python -m src.main
```

### Tests ausfÃ¼hren

```bash
# Alle Tests
pytest

# Mit Coverage
pytest --cov=src

# Nur Unit Tests
pytest tests/test_tools/ tests/test_engine/

# Integration Tests (benÃ¶tigt echte DB)
pytest tests/test_real_database.py -v
```

### Codebase in KnowWhere laden

```bash
# Indexiere die gesamte Codebase fÃ¼r semantische Suche
python scripts/ingest_codebase.py
```

---

## ğŸ› Troubleshooting

### Container ist "unhealthy"
Das `/health` Endpoint existiert nicht bei FastMCP - kann ignoriert werden. Die MCP-FunktionalitÃ¤t ist nicht betroffen.

### "Tool not found" in Cursor
1. MCP Status prÃ¼fen (Cursor â†’ Settings â†’ MCP)
2. Disconnecten und neu connecten
3. Cursor neu starten

### Memories werden nicht gefunden
**User-ID Mismatch!** Stelle sicher, dass die gleiche User-ID fÃ¼r Speichern und Abrufen verwendet wird.

In `src/main.py`:
```python
DEFAULT_USER_ID = UUID("deine-user-id-hier")
```

### "Connection refused" zu Supabase
Verwende die **Session Pooler** URL (Port 5432), nicht die Direct Connection URL.

### Redis nicht erreichbar
Redis ist optional. Der Server funktioniert auch ohne Cache, aber langsamer.

---

## ğŸš¢ Production Deployment

### Railway (empfohlen)

1. Fork zu deinem GitHub
2. Neues Railway Projekt erstellen
3. Add-ons: PostgreSQL, Redis
4. Environment Variables setzen
5. `railway.toml` wird automatisch erkannt

### Docker (Self-Hosted)

```bash
# Build
docker build -t knowwhere-mcp:latest .

# Run
docker run -d \
  --name knowwhere \
  -p 8000:8000 \
  -e DATABASE_URL="postgresql://..." \
  -e OPENAI_API_KEY="sk-..." \
  -e ANTHROPIC_API_KEY="sk-ant-..." \
  -e MCP_TRANSPORT="sse" \
  knowwhere-mcp:latest
```

---

## ğŸ“š Erkenntnisse aus der Entwicklung

### Wichtige Design-Entscheidungen

1. **SSE Transport fÃ¼r Docker**: stdio funktioniert nicht in containerisierten Umgebungen. Verwende `MCP_TRANSPORT=sse`.

2. **User-ID Management**: Im Debug-Modus wird eine Default-User-ID verwendet. Stelle sicher, dass alle Memories unter der gleichen ID gespeichert werden.

3. **Cursor Rules**: Claude entscheidet selbst, wann es Tools nutzt. Mit einer Cursor Rule kannst du automatische Memory-Suche erzwingen.

4. **Supabase Session Pooler**: Verwende die Session Pooler URL (5432) statt Direct Connection fÃ¼r bessere Performance.

5. **Claim Extraction**: Der LLM-Prompt fÃ¼r Claim-Extraktion ist kritisch. Aktuell optimiert fÃ¼r:
   - PersÃ¶nliche PrÃ¤ferenzen (Wichtigkeit 8-10)
   - Projekt-Fakten (Wichtigkeit 6-8)
   - Learnings und Erkenntnisse (Wichtigkeit 5-7)
   - Entscheidungen (Wichtigkeit 7-9)

6. **JSONB Handling**: PostgreSQL JSONB Felder mÃ¼ssen explizit zu JSON-Strings konvertiert werden beim INSERT und beim SELECT zurÃ¼ck geparst werden.

---

## ğŸ¤ Contributing

1. Fork das Repository
2. Feature Branch erstellen (`git checkout -b feature/amazing-feature`)
3. Ã„nderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request Ã¶ffnen

---

## ğŸ“„ License

MIT License - siehe [LICENSE](LICENSE) fÃ¼r Details.

---

## ğŸ”— Links

- **Repository**: [github.com/nimarfranklin/KW_Mem_MCP_Server](https://github.com/nimarfranklin/KW_Mem_MCP_Server)
- **MCP Protocol**: [modelcontextprotocol.io](https://modelcontextprotocol.io)
- **Supabase**: [supabase.com](https://supabase.com)
- **FastMCP**: [github.com/jlowin/fastmcp](https://github.com/jlowin/fastmcp)

---

## ğŸ“‹ Recent Updates (v1.1.0)

### ğŸš€ Performance Optimierungen
- **5x schnellere Consolidation**: Parallele Entity Extraction und Batch Embeddings
- **Batch Processing**: Gleichzeitige Verarbeitung mehrerer Memories
- **Optimized Connection Pooling**: Verbesserte Datenbank-Verbindungen
- **Async Improvements**: Mehr Parallelisierung in unabhÃ¤ngigen Operationen

### ğŸ“¡ MCP Protocol Erweiterungen
- **Neue MCP Resources**: `health://status`, `system://capabilities`, `user://{id}/stats`, `user://{id}/preferences`, `user://{id}/memories`, `user://{id}/entities`
- **MCP Prompts**: `memory_guided_creation`, `preference_analysis`, `learning_session_analysis`, `troubleshooting_workflow`
- **Sampling Support**: Effiziente Pagination fÃ¼r groÃŸe Resultate
- **Progress Notifications**: Fortschrittsanzeige fÃ¼r langlaufende Operationen

### ğŸ—ï¸ Architektur Verbesserungen
- **Dependency Injection Container**: Saubere Service-Management
- **Service Abstraction**: Bessere Testbarkeit und Wartbarkeit
- **Batch Memory Processing**: Neue `process_memories_batch()` Methode

### ğŸ”§ Developer Experience
- **Erweiterte System Capabilities**: Detaillierte Feature-Dokumentation
- **Verbesserte Error Handling**: Bessere Fehlermeldungen und Logging
- **Performance Monitoring**: Detaillierte Statistiken und Metriken

---

**Made with â¤ï¸ for persistent AI memory**
