# Knowwhere Memory MCP Server

**The persistent, intelligent memory layer that makes AI agents remember everythingâ€”deployable anywhere, integrated nowhere.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

Knowwhere Memory MCP Server is a vendor-agnostic, distributed memory infrastructure for AI agents that integrates with any AI service via the [Model Context Protocol (MCP)](https://modelcontextprotocol.io).

### Key Features

- **ğŸ§  Multimodal Memory Storage** - Episodic, semantic, preference, procedural, and meta-cognitive memories
- **ğŸ” Intelligent Semantic Search** - Vector similarity search with pgvector
- **ğŸ”„ Session Consolidation** - Automatically extract memories from conversations
- **ğŸ“Š Evolution Tracking** - Track how preferences change over time
- **ğŸ”’ GDPR Compliant** - Data export and deletion support
- **ğŸŒ Vendor Agnostic** - Works with Claude, GPT, Grok, Gemini via MCP

## Quick Start

FÃ¼r eine schnelle Testinstallation mit Docker:

```bash
git clone https://github.com/your-org/knowwhere-memory-mcp.git
cd knowwhere-memory-mcp
cp .env.example .env
# Editiere .env mit deinen API-Keys
docker-compose up -d
```

---

## Detaillierte Installationsanleitung

### Inhaltsverzeichnis

1. [Systemvoraussetzungen](#1-systemvoraussetzungen)
2. [Lokale Entwicklungsumgebung](#2-lokale-entwicklungsumgebung)
3. [Datenbank-Setup](#3-datenbank-setup)
4. [Redis Cache Setup](#4-redis-cache-setup)
5. [Umgebungsvariablen konfigurieren](#5-umgebungsvariablen-konfigurieren)
6. [Server starten](#6-server-starten)
7. [Docker Installation](#7-docker-installation)
8. [Produktions-Deployment](#8-produktions-deployment)
9. [Fehlerbehebung](#9-fehlerbehebung)

---

### 1. Systemvoraussetzungen

#### Mindestanforderungen

| Komponente | Version | Hinweis |
|-----------|---------|---------|
| **Python** | 3.11+ | [Download](https://www.python.org/downloads/) |
| **PostgreSQL** | 14+ | Mit pgvector Extension |
| **Redis** | 7.0+ | Optional, aber empfohlen |
| **Tesseract** | 5.0+ | Nur fÃ¼r Dokument-OCR |

#### BenÃ¶tigte API-Keys

| Service | Zweck | Link |
|---------|-------|------|
| **OpenAI** | Embeddings (text-embedding-3-large) | [API Keys](https://platform.openai.com/api-keys) |
| **Anthropic** ODER **OpenAI** | LLM fÃ¼r Consolidation | [Console](https://console.anthropic.com/) |
| **AWS S3 / Cloudflare R2** | Dokumenten-Upload (optional) | - |

---

### 2. Lokale Entwicklungsumgebung

#### 2.1 Repository klonen

```bash
git clone https://github.com/your-org/knowwhere-memory-mcp.git
cd knowwhere-memory-mcp
```

#### 2.2 Python Virtual Environment erstellen

**macOS / Linux:**
```bash
python3.11 -m venv venv
source venv/bin/activate
```

**Windows (PowerShell):**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Windows (CMD):**
```cmd
python -m venv venv
venv\Scripts\activate.bat
```

#### 2.3 Dependencies installieren

```bash
# Produktions-Dependencies
pip install -r requirements.txt

# Entwickler-Dependencies (Tests, Linting)
pip install -e ".[dev]"
```

#### 2.4 ÃœberprÃ¼fung der Installation

```bash
python -c "import fastmcp; print('âœ… FastMCP:', fastmcp.__version__)"
python -c "import asyncpg; print('âœ… asyncpg installiert')"
python -c "import anthropic; print('âœ… Anthropic SDK installiert')"
```

---

### 3. Datenbank-Setup

#### Option A: PostgreSQL lokal installieren

**macOS (Homebrew):**
```bash
brew install postgresql@16
brew services start postgresql@16

# pgvector Extension installieren
brew install pgvector
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install postgresql-16 postgresql-16-pgvector

sudo systemctl start postgresql
sudo systemctl enable postgresql
```

**Windows:**
1. Download PostgreSQL von [postgresql.org](https://www.postgresql.org/download/windows/)
2. pgvector manuell installieren: [pgvector Windows Guide](https://github.com/pgvector/pgvector#windows)

#### Option B: Supabase verwenden (empfohlen fÃ¼r Produktion)

1. Erstelle ein Projekt auf [supabase.com](https://supabase.com)
2. pgvector ist bereits aktiviert
3. Kopiere die Connection URL aus Settings â†’ Database

#### 3.1 Datenbank und Benutzer erstellen

```bash
# Als postgres User anmelden
sudo -u postgres psql

# In psql:
CREATE USER knowwhere WITH PASSWORD 'sicheres_passwort_hier';
CREATE DATABASE knowwhere OWNER knowwhere;
GRANT ALL PRIVILEGES ON DATABASE knowwhere TO knowwhere;

# pgvector Extension aktivieren (als Superuser)
\c knowwhere
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pg_trgm;

\q
```

#### 3.2 Schema-Migration ausfÃ¼hren

```bash
# Initiales Schema
psql -h localhost -U knowwhere -d knowwhere -f migrations/001_initial_schema.sql

# Row-Level Security (optional, fÃ¼r Multi-Tenant)
psql -h localhost -U knowwhere -d knowwhere -f migrations/002_enable_rls.sql
```

#### 3.3 Migration verifizieren

```bash
psql -h localhost -U knowwhere -d knowwhere -c "\dt"
```

Erwartete Tabellen:
```
 Schema |         Name          | Type  |  Owner   
--------+-----------------------+-------+----------
 public | access_logs           | table | knowwhere
 public | api_keys              | table | knowwhere
 public | consolidation_history | table | knowwhere
 public | document_chunks       | table | knowwhere
 public | files                 | table | knowwhere
 public | knowledge_edges       | table | knowwhere
 public | memories              | table | knowwhere
 public | schema_migrations     | table | knowwhere
 public | users                 | table | knowwhere
```

---

### 4. Redis Cache Setup

Redis ist optional, aber **dringend empfohlen** fÃ¼r:
- Rate Limiting
- Embedding-Caching (spart API-Kosten)
- Session State

#### Option A: Redis lokal installieren

**macOS:**
```bash
brew install redis
brew services start redis

# Testen
redis-cli ping  # Sollte "PONG" zurÃ¼ckgeben
```

**Ubuntu/Debian:**
```bash
sudo apt install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server

redis-cli ping
```

**Windows:**
```bash
# Mit WSL2 oder Docker empfohlen
docker run -d --name redis -p 6379:6379 redis:7-alpine
```

#### Option B: Redis Cloud verwenden

- [Upstash](https://upstash.com) (Serverless Redis, Free Tier)
- [Redis Cloud](https://redis.com/cloud/)

---

### 5. Umgebungsvariablen konfigurieren

#### 5.1 Template kopieren

```bash
cp .env.example .env
```

#### 5.2 .env Datei editieren

```bash
# Mit deinem bevorzugten Editor
nano .env
# oder
code .env
```

#### 5.3 Minimale Konfiguration

```env
# ============================================
# PFLICHT-KONFIGURATION
# ============================================

# Datenbank
DATABASE_URL=postgresql://knowwhere:dein_passwort@localhost:5432/knowwhere

# Supabase (fÃ¼r Auth, kann lokal leer sein)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your-anon-key

# OpenAI fÃ¼r Embeddings
OPENAI_API_KEY=sk-proj-...

# LLM fÃ¼r Consolidation (wÃ¤hle eines)
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-api03-...

# ============================================
# OPTIONALE KONFIGURATION
# ============================================

# Redis (dringend empfohlen)
REDIS_URL=redis://localhost:6379

# Debug-Modus (fÃ¼r Entwicklung)
DEBUG=true

# JWT Secret (WICHTIG: in Produktion Ã¤ndern!)
JWT_SECRET_KEY=dein-super-geheimes-jwt-secret-min-32-zeichen
```

#### 5.4 VollstÃ¤ndige Konfigurationsreferenz

| Variable | Pflicht | Standard | Beschreibung |
|----------|---------|----------|--------------|
| `DATABASE_URL` | âœ… | - | PostgreSQL Connection String |
| `OPENAI_API_KEY` | âœ… | - | FÃ¼r Embeddings |
| `LLM_PROVIDER` | âœ… | `anthropic` | `anthropic` oder `openai` |
| `ANTHROPIC_API_KEY` | Wenn LLM=anthropic | - | Claude API Key |
| `REDIS_URL` | âŒ | `redis://localhost:6379` | Cache URL |
| `JWT_SECRET_KEY` | âš ï¸ Produktion | Fallback | Min. 32 Zeichen |
| `RATE_LIMIT_ENABLED` | âŒ | `true` | Rate Limiting aktiv |
| `RATE_LIMIT_REQUESTS_PER_MINUTE` | âŒ | `100` | Requests pro Minute |
| `STORAGE_PROVIDER` | âŒ | `s3` | `s3`, `r2`, `gcs` |
| `STORAGE_BUCKET` | âŒ | `knowwhere-documents` | Bucket Name |

---

### 6. Server starten

#### 6.1 Entwicklungsmodus

```bash
# Aktiviere venv falls nÃ¶tig
source venv/bin/activate

# Server starten
python -m src.main
```

Erwartete Ausgabe:
```
2024-01-17T10:30:00.000Z [info] Knowwhere Memory MCP Server starting host=0.0.0.0 port=8000 debug=true
2024-01-17T10:30:00.100Z [info] Database connected
2024-01-17T10:30:00.150Z [info] Redis cache connected
2024-01-17T10:30:00.200Z [info] Audit logger started
2024-01-17T10:30:00.210Z [info] Rate limiter initialized
```

#### 6.2 Health Check

```bash
# In einem neuen Terminal
curl http://localhost:8000/health || echo "Server lÃ¤uft als MCP, nicht als HTTP"
```

#### 6.3 Mit Claude Desktop verbinden

Editiere `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) oder `%APPDATA%\Claude\claude_desktop_config.json` (Windows):

```json
{
  "mcpServers": {
    "knowwhere": {
      "command": "/pfad/zu/venv/bin/python",
      "args": ["-m", "src.main"],
      "cwd": "/pfad/zu/knowwhere-memory-mcp",
      "env": {
        "DATABASE_URL": "postgresql://knowwhere:passwort@localhost:5432/knowwhere",
        "OPENAI_API_KEY": "sk-...",
        "LLM_PROVIDER": "anthropic",
        "ANTHROPIC_API_KEY": "sk-ant-..."
      }
    }
  }
}
```

Starte Claude Desktop neu, um die Ã„nderungen zu Ã¼bernehmen.

---

### 7. Docker Installation

#### 7.1 Docker Compose (empfohlen fÃ¼r lokale Entwicklung)

```bash
# .env konfigurieren
cp .env.example .env
nano .env

# Alle Services starten
docker-compose up -d

# Logs anzeigen
docker-compose logs -f app
```

Das startet:
- **app**: Knowwhere MCP Server
- **db**: PostgreSQL 16 mit pgvector
- **redis**: Redis 7

#### 7.2 Nur Datenbank & Redis mit Docker

Falls du den Server lokal entwickeln willst:

```bash
# Nur PostgreSQL und Redis
docker-compose up -d db redis

# Server lokal starten
source venv/bin/activate
python -m src.main
```

#### 7.3 Docker Image bauen

```bash
# Image bauen
docker build -t knowwhere-mcp:latest .

# Container starten
docker run -d \
  --name knowwhere \
  -p 8000:8000 \
  -e DATABASE_URL="postgresql://..." \
  -e OPENAI_API_KEY="sk-..." \
  knowwhere-mcp:latest
```

---

### 8. Produktions-Deployment

#### 8.1 Railway (empfohlen)

1. Forke das Repository zu deinem GitHub
2. Erstelle ein neues Projekt auf [railway.app](https://railway.app)
3. FÃ¼ge Services hinzu:
   - **PostgreSQL** (Add-on)
   - **Redis** (Add-on)
4. Verbinde dein GitHub Repository
5. Setze Umgebungsvariablen im Dashboard:
   ```
   OPENAI_API_KEY=sk-...
   LLM_PROVIDER=anthropic
   ANTHROPIC_API_KEY=sk-ant-...
   JWT_SECRET_KEY=...
   ```
6. Railway erkennt `railway.toml` und deployed automatisch

#### 8.2 Render

1. Erstelle einen neuen **Web Service**
2. Verbinde GitHub Repository
3. Build Command: `pip install -r requirements.txt`
4. Start Command: `gunicorn src.main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:$PORT`
5. FÃ¼ge PostgreSQL und Redis als Add-ons hinzu

#### 8.3 AWS / GCP / Azure

FÃ¼r Self-Hosting mit Kubernetes:

```bash
# Docker Image zu Registry pushen
docker tag knowwhere-mcp:latest your-registry.io/knowwhere-mcp:latest
docker push your-registry.io/knowwhere-mcp:latest

# Kubernetes Deployment (Beispiel)
kubectl apply -f k8s/deployment.yaml
```

---

### 9. Fehlerbehebung

#### âŒ "FATAL: password authentication failed"

```bash
# PostgreSQL Benutzer neu erstellen
sudo -u postgres psql
ALTER USER knowwhere WITH PASSWORD 'neues_passwort';
```

#### âŒ "extension vector does not exist"

```bash
# pgvector nachinstallieren
# macOS:
brew install pgvector

# Dann in psql:
CREATE EXTENSION vector;
```

#### âŒ "Redis connection refused"

```bash
# Redis Status prÃ¼fen
redis-cli ping

# Falls nicht lÃ¤uft:
# macOS:
brew services start redis

# Linux:
sudo systemctl start redis-server
```

#### âŒ "OpenAI API error: rate limit"

Die Standard-Embedding-Rate ist begrenzt. LÃ¶sungen:
1. Redis-Cache aktivieren (reduziert API-Calls drastisch)
2. OpenAI Tier upgraden
3. `RATE_LIMIT_REQUESTS_PER_MINUTE` reduzieren

#### âŒ "JWT secret key not set"

```bash
# Sicheren Key generieren
python -c "import secrets; print(secrets.token_urlsafe(32))"

# In .env eintragen:
JWT_SECRET_KEY=dein_generierter_key
```

#### âŒ Module nicht gefunden

```bash
# Sicherstellen, dass venv aktiviert ist
which python  # Sollte venv/bin/python zeigen

# Dependencies neu installieren
pip install -r requirements.txt --force-reinstall
```

---

### NÃ¤chste Schritte

Nach erfolgreicher Installation:

1. **Ersten Memory erstellen**: Teste mit Claude Desktop den `remember` Befehl
2. **API-Key erstellen**: FÃ¼r Server-zu-Server Integration
3. **Monitoring einrichten**: Logs in Grafana/Datadog integrieren
4. **Backups konfigurieren**: PostgreSQL pg_dump automatisieren

## Usage

### Connecting from Claude Desktop

Add to your Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "knowwhere": {
      "command": "python",
      "args": ["-m", "src.main"],
      "cwd": "/path/to/knowwhere-memory-mcp"
    }
  }
}
```

### Available Tools

#### 1. `remember` - Store a Memory

```json
{
  "content": "User prefers async/await over callbacks",
  "memory_type": "preference",
  "importance": 8
}
```

#### 2. `recall` - Search Memories

```json
{
  "query": "What programming patterns does the user prefer?",
  "limit": 5
}
```

#### 3. `consolidate_session` - Process Conversation

```json
{
  "session_transcript": "User: I love TypeScript...",
  "conversation_id": "session-123"
}
```

#### 4. `analyze_evolution` - Track Changes

```json
{
  "entity_name": "TypeScript",
  "time_window": "last_30_days"
}
```

#### 5. `export_memories` - Export Data

```json
{
  "format": "json",
  "include_embeddings": false
}
```

#### 6. `delete_memory` - Remove Memory

```json
{
  "memory_id": "uuid-here",
  "hard_delete": false
}
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM Clients                               â”‚
â”‚            (Claude, Grok, Gemini, Custom)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ MCP Protocol
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastMCP Server                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   6 MCP Tools                          â”‚ â”‚
â”‚  â”‚  remember | recall | consolidate | analyze | export |  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚               Memory Engine                            â”‚ â”‚
â”‚  â”‚  MemoryProcessor | ConsolidationEngine | KnowledgeGraphâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Storage Layer                             â”‚ â”‚
â”‚  â”‚      PostgreSQL + pgvector    |    Redis Cache         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
knowwhere-memory-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastMCP entry point
â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”œâ”€â”€ tools/               # MCP tool implementations
â”‚   â”œâ”€â”€ engine/              # Business logic
â”‚   â”œâ”€â”€ storage/             # Data access layer
â”‚   â”œâ”€â”€ services/            # External service clients
â”‚   â””â”€â”€ models/              # Pydantic models
â”œâ”€â”€ migrations/              # Database migrations
â”œâ”€â”€ tests/                   # Test suite
â”œâ”€â”€ docker-compose.yml       # Local development
â”œâ”€â”€ Dockerfile              # Production container
â””â”€â”€ railway.toml            # Railway deployment
```

## Deployment

### Docker

```bash
docker-compose up -d
```

### Railway

1. Connect your GitHub repository to Railway
2. Add PostgreSQL and Redis add-ons
3. Set environment variables in Railway dashboard
4. Deploy!

### Vercel (Serverless)

Note: Vercel has execution time limits. Recommended for light workloads only.

## Development

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Run linter
ruff check src/

# Type checking
mypy src/
```

## API Documentation

Full OpenAPI specification available at `/docs` when running in debug mode.

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

MIT License - see [LICENSE](LICENSE) for details.

## Support

- ğŸ“š [Documentation](https://docs.knowwhere.ai)
- ğŸ’¬ [Discord Community](https://discord.gg/knowwhere)
- ğŸ› [Issue Tracker](https://github.com/your-org/knowwhere-memory-mcp/issues)

---

**Made with â¤ï¸ by the Knowwhere Team**
